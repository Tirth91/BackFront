<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Agora Zoom-Style Video Call + Gesture</title>
  <script src="https://download.agora.io/sdk/release/AgoraRTC_N-4.20.0.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
  <style>
    body {
      font-family: sans-serif;
      margin: 0;
      padding: 20px;
      background: #f4f4f4;
    }

    h2 {
      margin-bottom: 10px;
    }

    #controls {
      margin-bottom: 10px;
    }

    #video-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
      gap: 10px;
    }

    .video-box {
      background: #000;
      width: 100%;
      aspect-ratio: 4 / 3;
      position: relative;
      border-radius: 10px;
      overflow: hidden;
    }

    .prediction {
      position: absolute;
      bottom: 5px;
      left: 5px;
      right: 5px;
      text-align: center;
      color: #fff;
      font-weight: bold;
      background: rgba(0, 0, 0, 0.5);
      padding: 2px;
      font-size: 1rem;
    }
  </style>
</head>
<body>

  <h2>Agora + Gesture Recognition</h2>

  <div id="controls">
    <input id="channel" type="text" placeholder="Enter Channel Name" />
    <button onclick="join()">Join</button>
    <button onclick="leave()">Leave</button>
  </div>

  <div id="video-grid"></div>

  <canvas id="gesture-canvas" width="224" height="224" style="display:none;"></canvas>

  <script>
    const APP_ID = "0f3fde8ae17c4048bcfc8d69286bc851"; // Replace with your Agora App ID
    const TOKEN = null;
    let CHANNEL = "";

    let client = AgoraRTC.createClient({ mode: "rtc", codec: "vp8" });
    let localTracks = { videoTrack: null, audioTrack: null };
    let localUid = null;
    const remoteUsers = {};
    let gestureModel = null;

    const labelMap = [
      "1L", "1R", "2L", "2R", "3L", "3R", "4L", "4R", "5R", "6L", "6R",
      "7L", "7R", "8L", "8R", "9L", "9R", "A", "B", "C", "D", "L"
    ];

    async function loadGestureModel() {
      gestureModel = await tf.loadGraphModel("landmark_model_tfjs/model.json");
      console.log("Gesture model loaded.");
    }

    async function join() {
      CHANNEL = document.getElementById("channel").value;
      if (!CHANNEL) return alert("Enter a channel name");

      await loadGestureModel();

      await client.join(APP_ID, CHANNEL, TOKEN, null);

      localTracks.audioTrack = await AgoraRTC.createMicrophoneAudioTrack();
      localTracks.videoTrack = await AgoraRTC.createCameraVideoTrack();

      localUid = client.uid;
      addVideoBox(localUid, true);
      localTracks.videoTrack.play(`user-${localUid}`);

      await client.publish(Object.values(localTracks));
      console.log("Published local tracks");

      client.on("user-published", handleUserPublished);
      client.on("user-unpublished", handleUserUnpublished);
      client.on("user-left", handleUserLeft);

      startGestureDetection(localTracks.videoTrack);
    }

    async function leave() {
      for (let trackName in localTracks) {
        const track = localTracks[trackName];
        if (track) {
          track.stop();
          track.close();
        }
      }

      await client.leave();
      document.getElementById("video-grid").innerHTML = "";
      console.log("Left channel");
    }

    function addVideoBox(uid, isLocal = false) {
      if (document.getElementById(`user-${uid}`)) return;
      const box = document.createElement("div");
      box.id = `user-${uid}`;
      box.className = "video-box";

      if (isLocal) {
        const predText = document.createElement("div");
        predText.className = "prediction";
        predText.id = "gesture-label";
        predText.innerText = "Gesture: ...";
        box.appendChild(predText);
      }

      document.getElementById("video-grid").appendChild(box);
    }

    function removeVideoBox(uid) {
      const el = document.getElementById(`user-${uid}`);
      if (el) el.remove();
    }

    async function handleUserPublished(user, mediaType) {
      await client.subscribe(user, mediaType);
      console.log("Subscribed to user:", user.uid);

      addVideoBox(user.uid);

      if (mediaType === "video") {
        user.videoTrack.play(`user-${user.uid}`);
      }

      if (mediaType === "audio") {
        user.audioTrack.play();
      }

      remoteUsers[user.uid] = user;
    }

    function handleUserUnpublished(user) {
      removeVideoBox(user.uid);
    }

    function handleUserLeft(user) {
      removeVideoBox(user.uid);
      delete remoteUsers[user.uid];
    }

    function startGestureDetection(videoTrack) {
      const canvas = document.getElementById("gesture-canvas");
      const ctx = canvas.getContext("2d");
      const videoElement = document.createElement("video");
      videoElement.playsInline = true;
      videoElement.muted = true;

      const stream = new MediaStream([videoTrack.getMediaStreamTrack()]);
      videoElement.srcObject = stream;
      videoElement.play();

      async function detect() {
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
        const input = tf.browser.fromPixels(canvas).expandDims(0).toFloat().div(255);

        const prediction = await gestureModel.predict(input).data();
        const maxIndex = prediction.indexOf(Math.max(...prediction));
        const label = labelMap[maxIndex];

        const labelDiv = document.getElementById("gesture-label");
        if (labelDiv) labelDiv.innerText = `Gesture: ${label}`;

        tf.dispose(input);
        requestAnimationFrame(detect);
      }

      detect();
    }
  </script>

</body>
</html>
